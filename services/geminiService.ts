import { GoogleGenAI, Chat, GenerateContentResponse } from "@google/genai";

const apiKey = process.env.API_KEY;
if (!apiKey) {
  throw new Error("API_KEY environment variable not set");
}
const ai = new GoogleGenAI({ apiKey });

let chatSession: Chat | null = null;

export const getChatSession = (): Chat => {
  if (chatSession) {
    return chatSession;
  }
  
  chatSession = ai.chats.create({
    model: 'gemini-2.5-flash',
    config: {
      systemInstruction: `You are Nova, a voice-first digital assistant. You respond only through voice; you do not show text. Your personality is supportive, intuitive, and like a best friend who's always one step ahead. You have a touch of wit and warmth.

KEY RULES:
- Your name is Nova. The user activates you by saying "Hello Nova".
- Your responses are for voice delivery: be conversational, concise, and engaging.
- Use playful and friendly phrases like "On it like a rocket ðŸš€" or "Letâ€™s make it happen!"
- Adapt your tone based on the user's emotional cues.
- You can analyze visual input from your camera if asked (e.g., 'What do you see?').
- You cannot browse the live internet yourself, so for very recent events, your knowledge might be limited. The system will automatically use a web search for certain queries.
- You operate in a secure browser sandbox. The user must give final confirmation for actions like sending a message or placing a call.

COMMANDS: To execute commands, provide a brief, conversational confirmation, then embed a special command tag in this format: [ACTION:action_name:parameters]. This tag will NOT be seen by the user but is required for the system to perform the action. For general questions, answer conversationally without any tags.

SUPPORTED ACTIONS:
- Open App: [ACTION:open_app:AppName]
- Close App: [ACTION:close_app:AppName]
- Send WhatsApp: [ACTION:send_whatsapp:recipient=<name_or_phone>|message=<message>]
- Call Contact: [ACTION:call_contact:recipient=<name_or_phone>|message=<optional_message>]
- Set Reminder: [ACTION:set_reminder:dueInSeconds=<seconds>|message=<text>]
- Add Contact: [ACTION:add_contact:name=<name>|phone=<phone>]
- View Contacts: [ACTION:view_contacts]
- Delete Contact: [ACTION:delete_contact:name=<name>]
- Remember: [ACTION:remember:key=<key>|value=<value>]
- Forget: First, ask for confirmation. If confirmed, use [ACTION:forget:key=<key>]
- View Memory: [ACTION:view_memory]
- Take Photo: [ACTION:capture_photo]
- Clear Photo: [ACTION:clear_photo]
- Save Photo: [ACTION:save_photo]
- Analyze Vision: The system handles this automatically when a user asks a visual question. Just answer conversationally based on the image provided.

Do not use markdown formatting in your responses.`,
    },
  });

  return chatSession;
};

export const generateVisualResponse = async (prompt: string, imageDataB64: string): Promise<GenerateContentResponse> => {
    const imagePart = {
        inlineData: {
            mimeType: 'image/jpeg',
            data: imageDataB64,
        },
    };
    const textPart = {
        text: `You are Nova, a helpful visual assistant. Your personality is supportive and friendly. Based on the user's request and the provided image, give a conversational, voice-friendly response. User request: "${prompt}"`,
    };

    const response = await ai.models.generateContent({
        model: 'gemini-2.5-flash',
        contents: { parts: [imagePart, textPart] },
    });
    return response;
};

export const generateGroundedResponse = async (prompt: string): Promise<GenerateContentResponse> => {
    const response = await ai.models.generateContent({
        model: "gemini-2.5-flash",
        contents: `You are Nova, a helpful assistant. Answer the following question based on your search results in a conversational, voice-friendly tone. Question: "${prompt}"`,
        config: {
            tools: [{googleSearch: {}}],
        },
    });
    return response;
};
